# PD Configuration.

name = "pd"
data-dir = "default.pd"

client-urls = "http://127.0.0.1:2379"
## if not set, use ${client-urls}
advertise-client-urls = ""

peer-urls = "http://127.0.0.1:2380"
## if not set, use ${peer-urls}
advertise-peer-urls = ""

initial-cluster = "pd=http://127.0.0.1:2380"
initial-cluster-state = "new"

lease = 3
tso-save-interval = "3s"

enable-prevote = true

[security]
## Path of file that contains list of trusted SSL CAs. if set, following four settings shouldn't be empty
cacert-path = ""
## Path of file that contains X509 certificate in PEM format.
cert-path = ""
## Path of file that contains X509 key in PEM format.
key-path = ""

cert-allowed-cn = ["example.com"]

[log]
level = "info"

## log format, one of json, text, console
# format = "text"

## disable automatic timestamps in output
# disable-timestamp = false

# file logging
[log.file]
# filename = ""
## max log file size in MB
# max-size = 300
## max log file keep days
# max-days = 28
## maximum number of old log files to retain
# max-backups = 7
## rotate log by day
# log-rotate = true

[metric]
## prometheus client push interval, set "0s" to disable prometheus.
interval = "15s"
## prometheus pushgateway address, leaves it empty will disable prometheus.
address = ""

[pd-server]
## the metric storage is the cluster metric storage. This is use for query metric data.
## Currently we use prometheus as metric storage, we may use PD/TiKV as metric storage later.
## For usability, recommended to temporarily set it to the prometheus address, eg: http://127.0.0.1:9090
metric-storage = ""

[schedule]
max-merge-region-size = 20
max-merge-region-keys = 200000
split-merge-interval = "1h"
max-snapshot-count = 3
max-pending-peer-count = 16
max-store-down-time = "30m"
leader-schedule-limit = 4
region-schedule-limit = 2048
replica-schedule-limit = 64
merge-schedule-limit = 8
hot-region-schedule-limit = 4
## There are some policies supported: ["count", "size"], default: "count"
# leader-schedule-policy = "count"
## When the score difference between the leader or Region of the two stores is
## less than specified multiple times of the Region size, it is considered in balance by PD.
## If it equals 0.0, PD will automatically adjust it.
# tolerant-size-ratio = 0.0

## This three parameters control the merge scheduler behavior.
## If it is true, it means a region can only be merged into the next region of it.
# enable-one-way-merge = false
## If it is true, it means two region within different tables can be merged.
## This option only works when key type is "table".
# enable-cross-table-merge = false

## customized schedulers, the format is as below
## if empty, it will use balance-leader, balance-region, hot-region as default
# [[schedule.schedulers]]
# type = "evict-leader"
# args = ["1"]

[replication]
## The number of replicas for each region.
max-replicas = 3
## The label keys specified the location of a store.
## The placement priorities is implied by the order of label keys.
## For example, ["zone", "rack"] means that we should place replicas to
## different zones first, then to different racks if we don't have enough zones.
location-labels = []
## Strictly checks if the label of TiKV is matched with location labels.
# strictly-match-label = false

[label-property]
## Do not assign region leaders to stores that have these tags.
# [[label-property.reject-leader]]
# key = "zone"
# value = "cn1