apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Values.clusterName }}-pd
  labels:
    app.kubernetes.io/name: {{ template "tidb-cluster.name" . }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
    app.kubernetes.io/instance: {{ .Values.clusterName }}
    app.kubernetes.io/component: pd
    helm.sh/chart: {{ .Chart.Name }}-{{ .Chart.Version | replace "+"  "_" }}
data:
  startup-script: |-
    #!/bin/sh

    # This script is used to start pd containers in kubernetes cluster

    # Use DownwardAPIVolumeFiles to store informations of the cluster:
    # https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/#the-downward-api
    #
    #   runmode="normal/debug"
    #

    set -uo pipefail
    ANNOTATIONS="/etc/podinfo/annotations"
    # get statefulset ordinal index for current pod
    ORDINAL=$(echo ${HOSTNAME} | awk -F '-' '{print $NF}')

    if [[ ! -f "${ANNOTATIONS}" ]]
    then
        echo "${ANNOTATIONS} does't exist, exiting."
        exit 1
    fi
    source ${ANNOTATIONS} 2>/dev/null

    PEER_SERVICE_DOMAIN="${HOSTNAME}.${PEER_SERVICE_NAME}.${NAMESPACE}.svc"
    SERVICE_DOMAIN="${SERVICE_NAME}.${NAMESPACE}.svc"

    runmode=${runmode:-normal}
    if [[ X${runmode} == Xdebug ]]
    then
        echo "entering debug mode."
        tail -f /dev/null
    fi

    elapseTime=0
    period=1
    threshold=30
    while true; do
        sleep ${period}
        elapseTime=$(( elapseTime+period ))

        if [[ ${elapseTime} -ge ${threshold} ]]
        then
            echo "waiting for pd cluster ready timeout" >&2
            exit 1
        fi

        source ${ANNOTATIONS} 2>/dev/null
        if nslookup ${PEER_SERVICE_DOMAIN} 2>/dev/null
        then
            echo "nslookup domain ${HOSTNAME}.${PEER_SERVICE_NAME}.${NAMESPACE}.svc success"

            if [[ ${ORDINAL} -eq 0 ]]
            then
                [[ -z ${bootstrapping:-} ]] && continue
                [[ ${bootstrapping} == "true" ]] && break
            fi

            [[ -d /var/lib/pd/member/wal ]] && break
            wget -qO- ${SERVICE_DOMAIN}:2379/pd/api/v1/members 2>/dev/null
            [[ $? -eq 0 ]] && break
            echo "pd cluster is not ready now: ${SERVICE_DOMAIN}"
        else
            echo "nslookup domain ${PEER_SERVICE_DOMAIN} failed" >&2
        fi
    done

    ARGS="--data-dir=/var/lib/pd \
    --name=${HOSTNAME} \
    --peer-urls=http://0.0.0.0:2380 \
    --advertise-peer-urls=http://${HOSTNAME}.${PEER_SERVICE_NAME}.${NAMESPACE}.svc:2380 \
    --client-urls=http://0.0.0.0:2379 \
    --advertise-client-urls=http://${HOSTNAME}.${PEER_SERVICE_NAME}.${NAMESPACE}.svc:2379 \
    --config=/etc/pd/pd.toml \
    "

    replicas=${replicas:-3}
    if [[ ${ORDINAL} -eq 0 && ${bootstrapping:-} == "true" ]]
    then
        ARGS="${ARGS}--initial-cluster=${HOSTNAME}=http://${HOSTNAME}.${PEER_SERVICE_NAME}.${NAMESPACE}.svc:2380"
    else
        if [[ ${ORDINAL} -eq 0 ]]
        then
          TOP=$((replicas-1))
        else
          TOP=$((ORDINAL-1))
        fi

        ARGS="${ARGS}--join="
        for i in $(seq 0 ${TOP});
        do
            [[ ${i} -eq ${ORDINAL} ]] && continue
            ARGS="${ARGS}http://${SET_NAME}-${i}.${PEER_SERVICE_NAME}.${NAMESPACE}.svc:2380"
            if [[ ${i} -lt ${TOP} ]]
            then
                ARGS="${ARGS},"
            fi
        done
    fi

    echo "starting pd-server ..."
    echo "/pd-server ${ARGS}"
    exec /pd-server ${ARGS}
  config-file: |-
    {{- if .Values.pd.config }}
{{ .Values.pd.config | indent 4 }}
    {{- else }}
    # PD Configuration.

    name = "pd"
    data-dir = "default.pd"

    client-urls = "http://127.0.0.1:2379"
    # if not set, use ${client-urls}
    advertise-client-urls = ""

    peer-urls = "http://127.0.0.1:2380"
    # if not set, use ${peer-urls}
    advertise-peer-urls = ""

    initial-cluster = ""
    initial-cluster-state = ""

    lease = 3
    tso-save-interval = "3s"

    [security]
    # Path of file that contains list of trusted SSL CAs. if set, following four settings shouldn't be empty
    cacert-path = ""
    # Path of file that contains X509 certificate in PEM format.
    cert-path = ""
    # Path of file that contains X509 key in PEM format.
    key-path = ""

    [log]
    level = "{{ .Values.pd.logLevel }}"

    # log format, one of json, text, console
    #format = "text"

    # disable automatic timestamps in output
    #disable-timestamp = false

    # file logging
    [log.file]
    #filename = ""
    # max log file size in MB
    #max-size = 300
    # max log file keep days
    #max-days = 28
    # maximum number of old log files to retain
    #max-backups = 7
    # rotate log by day
    #log-rotate = true

    [metric]
    # prometheus client push interval, set "0s" to disable prometheus.
    interval = "15s"
    # prometheus pushgateway address, leaves it empty will disable prometheus.
    address = ""

    [schedule]
    max-merge-region-size = 0
    split-merge-interval = "1h"
    max-snapshot-count = 3
    max-pending-peer-count = 16
    max-store-down-time = "{{ .Values.pd.maxStoreDownTime }}"
    leader-schedule-limit = 4
    region-schedule-limit = 4
    replica-schedule-limit = 8
    merge-schedule-limit = 8
    tolerant-size-ratio = 5.0

    # customized schedulers, the format is as below
    # if empty, it will use balance-leader, balance-region, hot-region as default
    # [[schedule.schedulers]]
    # type = "evict-leader"
    # args = ["1"]

    [replication]
    # The number of replicas for each region.
    max-replicas = {{ .Values.pd.maxReplicas }}
    # The label keys specified the location of a store.
    # The placement priorities is implied by the order of label keys.
    # For example, ["zone", "rack"] means that we should place replicas to
    # different zones first, then to different racks if we don't have enough zones.
    location-labels = ["zone", "rack", "host"]

    [label-property]
    # Do not assign region leaders to stores that have these tags.
    #  [[label-property.reject-leader]]
    #  key = "zone"
    #  value = "cn1
    {{- end -}}
