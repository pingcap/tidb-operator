# TiBR

<!-- toc -->
- [Release Signoff Checklist](#release-signoff-checklist)
- [Summary](#summary)
- [Motivation](#motivation)
  - [Goals](#goals)
  - [Non-Goals](#non-goals)
- [Proposal](#proposal)
  - [User Stories](#user-stories)
    - [Story 1](#story-1)
    - [Story 2](#story-2)
- [Design Details](#design-details)
  - [API](#api)
  - [Test Plan](#test-plan)
  - [Feature Gate](#feature-gate)
<!-- /toc -->

## Release Signoff Checklist

Items marked with (R) are required *prior to targeting to a release*.

- [x] (R) This design doc has been discussed and approved
- [ ] (R) Test plan is in place
    - [ ] (R) e2e tests in kind
- [ ] (R) Graduation criteria is in place if required
- [ ] (R) User-facing documentation has been created in [pingcap/docs-tidb-operator]

## Summary

Support BR (Backup and Restore) management for cloud-storage-engine version TiDB clusters in TiDB Operator.

## Motivation

BR is a basic feature for TiDB clusters, which allows users backup their data and restore it when needed. This RFC proposes to implement BR management for cloud-storage-engine version TiDB clusters in TiDB Operator. 

### Goals

- Deploy BR components for cloud-storage-engine version TiDB clusters.

### Non-Goals

- Another BR management for non-cloud-storage-engine version TiDB clusters.

## Proposal

### User Stories

#### Story 1

As a TiDB user, I want to enable auto backup for a cloud-storage-engine version TiDB Cluster, so that I can backup my data periodically. I want to query existing backups and restore data from a specific backup.

#### Story 2

As a TiDB user, I want to enable backup gc mechanism and configure strategy, so that I can automatically delete old backups to save storage space.

## Design Details

### API

TiBR defines a BR service in a CRD. Optionally, the CRD can also define auto backup schedule. The corresponding controller will bootstrap a pod to provide BR api service and optionally make auto backup periodically. When users want to make backup or restore, users need to request the api service directly. The CRD contains the following fields:

```yaml
apiVersion: br.pingcap.com/v1alpha1
kind: TiBR
metadata:
  name: tibr-xxx
spec:
  cluster:
    name: basic
  autoSchedule:
    type: per-hour # per-day/per-hour/per-minute
    at:  10 # run backup at xx hour/minute of the day/hour
  image: <>
  config: <>
  resources: <>
  volumes: <>
  overlay: <>
```

TiBRGC defines GC (garbage collection) strategy for backups. The corresponding controller will bootstrap pods to run GC daily. The CRD contains the following fields:

```yaml
apiVersion: br.pingcap.com/v1alpha1
kind: TiBRGC
metadata:
  name: tibrgc-xxx
spec:
  cluster: 
    name: basic
  gcStrategy:
    type: "xxx" # define GC strategy type, only support 'tiered-storage' now
    tieredStrategies: # define details of tiered storage GC strategies
    - name: "to-t2-storage"
      timeThresholdDays: 7
      schedule: "0 0 * * *"
      resources: <>
      volumes: <>
      options: <>
    - name: "to-t3-storage"
      timeThresholdDays: 5
      schedule: "30 0 * * *"
      resources: <>
      volumes: <>
      options: <>
  image: <>
  overlay: # define overlay for BR GC pod
    pods:
    - name: to-t2-storage
      overlay: <>
    - name: to-t3-storage
      overlay: <>
```

### Test Plan

TBA

### Feature Gate
No feature gate
