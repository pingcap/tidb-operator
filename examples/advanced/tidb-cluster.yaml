apiVersion: pingcap.com/v1alpha1
kind: TidbCluster
metadata:
  name: advanced-tidb
  namespace: default

spec:
  #######################
  # Basic Configuration #
  #######################

  ## Configuration
  # TiDB cluster version
  version: "v4.0.8"

  ## Time zone of TiDB cluster Pods
  timezone: UTC

  ## serviceAccount specifies service account for PD/TiDB/TiKV/TiFlash/Pump/TiCDC components in this TidbCluster
  # serviceAccount: advanced-tidb

  ## ConfigUpdateStrategy determines how the configuration change is applied to the cluster.
  ## Valid values are `InPlace` and `RollingUpdate`
  ##   UpdateStrategy `InPlace` will update the ConfigMap of configuration in-place and an extra rolling-update of the
  ##   cluster component is needed to reload the configuration change.
  ##   UpdateStrategy `RollingUpdate` will create a new ConfigMap with the new configuration and rolling-update the
  ##   related components to use the new ConfigMap, that is, the new configuration will be applied automatically.
  configUpdateStrategy: RollingUpdate

  ## ImagePullPolicy of TiDB cluster Pods
  ## Ref: https://kubernetes.io/docs/concepts/configuration/overview/#container-images
  imagePullPolicy: IfNotPresent

  ## If secret image repo is used, ImagePullSecrets must be set
  ## Ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  # ImagePullSecrets: secretName

  ## Image used to tail slow log and set kernel parameters if necessary, must have `tail` and `sysctl` installed
  # helper:
  #   image: busybox:latest
  #   imagePullPolicy: IfNotPresent

  ## Enable PVC/PV reclaim for orphan PVC/PV left by statefulset scale-in
  enablePVReclaim: false

  ## Persistent volume reclaim policy applied to the PVC/PV consumed by the TiDB cluster, default to `Retain`.
  ## Note that the reclaim policy Recycle may not be supported by some storage types, .e.g. local.
  ## Ref: https://kubernetes.io/docs/tasks/administer-cluster/change-pv-reclaim-policy/
  pvReclaimPolicy: Retain

  ##########################
  # Advanced Configuration #
  ##########################

  ## when deploying a heterogeneous TiDB cluster, you MUST specify the cluster name to join here
  # cluster: tidb-cluster-to-join

  ## specify pdAddresses will make PD in this TiDB cluster to join another existing PD cluster
  ## PD will then start with arguments --join= instead of --initial-cluster=
  # pdAddresses:
  #   - http://cluster1-pd-0.cluster1-pd-peer.default.svc:2379
  #   - http://cluster1-pd-1.cluster1-pd-peer.default.svc:2379

  ## Enable mutual TLS connection between TiDB cluster components
  ## Ref: https://pingcap.com/docs/tidb-in-kubernetes/stable/enable-tls-between-components/
  # tlsCluster:
  #   enabled: true

  ## Annotations of TiDB cluster pods, will be overwritten by component annotation settings
  # annotations:
  #   node.kubernetes.io/instance-type: some-vm-type
  #   topology.kubernetes.io/region: some-region

  ## Specify node labels for pods scheduling, will be overwritten by component nodeSelector settings
  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  # nodeSelector:
  #   node-role.kubernetes.io/tidb: true

  ## Tolerations are applied to TiDB cluster pods, allowing (but do not require) pods to be scheduled onto nodes with matching taints.
  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  # tolerations:
  #   - effect: NoSchedule
  #     key: dedicated
  #     operator: Equal
  #     value: tidb

  ## Use the node network namespace, default to false
  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#host-namespaces
  hostNetwork: false

  ## specify resource requirements for discovery deployment
  # discovery:
  #   requests:
  #     memory: 128Mi
  #     cpu: 100m
  #   limits:
  #     memory: 256Mi
  #     cpu: 200m

  ## if true, this tidb cluster is paused and will not be synced by the controller
  # paused: false

  ## SchedulerName of TiDB cluster pods
  ## If specified, the pods will be dispatched by specified scheduler
  # schedulerName: tidb-scheduler

  ## Affinity for pod scheduling, will be overwritten by each cluster component's specific affinity setting
  ## Can reference to PD/TiDB/TiKV affinity settings, and ensure only cluster-wise general settings here
  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  # affinity: {}

  ## Specify pod priorities of pods in TidbCluster, default to empty
  ## Ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/
  # priorityClassName: system-cluster-critical

  ## Enable the dynamic configuration feature
  ## Currently only used for tikv --advertise-addr arg
  enableDynamicConfiguration: true

  ## set statefulsets' update strategy, can be overwritten by each component settings
  ## defaults to RollingUpdate
  ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  # statefulSetUpdateStrategy: RollingUpdate

  ## the FQDN of component services will be ended with clusterDomain here, in case you want to access TiDB clusters
  ## in different Kubernetes clusters, AKA vpc-native clusters. default to empty
  # clusterDomain: cluster-domain.example

  ###########################
  # TiDB Cluster Components #
  ###########################

  pd:
    ##########################
    # Basic PD Configuration #
    ##########################

    ## Base image of the component
    baseImage: pingcap/pd

    ## pd-server configuration
    ## Ref: https://docs.pingcap.com/tidb/stable/pd-configuration-file
    config: {}

    ## The desired replicas
    replicas: 3

    ## max inprogress failover PD pod counts
    # maxFailoverCount: 3

    ## describes the compute resource requirements and limits.
    ## Ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
    requests:
      cpu: 100m
      memory: 256Mi
      storage: 1Gi
    limits:
      cpu: 1000m
      memory: 2Gi
      storage: 10Gi

    ## define Kubernetes service for pd-server
    ## Ref: https://kubernetes.io/docs/concepts/services-networking/service/
    # service:
    #   type: ClusterIP
    #   annotations:
    #     foo: bar
    #   loadBalancerIP: load-balancer-ip
    #   clusterIP: cluster-ip
    #   portName: 2379

    #############################
    # Advanced PD Configuration #
    #############################

    ## Overwrite TiDB cluster level configurations
    # version: "v4.0.8"
    # imagePullPolicy: IfNotPresent
    # ImagePullSecrets: secretName
    # hostNetwork: false
    # serviceAccount: advanced-tidb-pd
    # priorityClassName: system-cluster-critical
    # schedulerName: tidb-scheduler
    # nodeSelector:
    #   app.kubernetes.io/component: pd
    # annotations:
    #   node.kubernetes.io/instance-type: some-vm-type
    # tolerations:
    #   - effect: NoSchedule
    #     key: dedicated
    #     operator: Equal
    #     value: pd
    # configUpdateStrategy: RollingUpdate
    # statefulSetUpdateStrategy: RollingUpdate

    ## List of environment variables to set in the container
    ## Note that the following env names cannot be used and may be overrided by TiDB Operator builtin envs
    ##   - NAMESPACE
    ##   - TZ
    ##   - SERVICE_NAME
    ##   - PEER_SERVICE_NAME
    ##   - HEADLESS_SERVICE_NAME
    ##   - SET_NAME
    ##   - HOSTNAME
    ##   - CLUSTER_NAME
    ##   - POD_NAME
    ##   - BINLOG_ENABLED
    ##   - SLOW_LOG_FILE
    ## Ref: https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/
    # env:
    #   - name: MY_ENV_1
    #     value: value1
    #   - name: MY_ENV_2
    #     valueFrom:
    #       fieldRef:
    #         fieldPath: status.myEnv2

    ## Custom sidecar containers can be injected into the PD pods,
    ## which can act as a logging/tracing agent or for any other use case
    # additionalContainers:
    #   - name: myCustomContainer
    #     image: ubuntu

    ## custom additional volumes in PD pods
    # additionalVolumes:
    #   - name: nfs
    #     nfs:
    #       server: 192.168.0.2
    #       path: /nfs

    ## custom additional volume mounts in PD pods
    # additionalVolumeMounts:
    #   - name: nfs
    #     mountPath: /nfs

    ## define the time period between pod Terminating and killed
    ## Ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#hook-handler-execution
    # terminationGracePeriodSeconds: 30s

    ## defines privilege and access control settings for PD pods
    ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
    # podSecurityContext:
    #   sysctls:
    #     - name: net.ipv4.tcp_syncookies
    #       value: 0

    ## when TLS cluster feature is enabled, TiDB Operator will automatically mount the certificates if mountClusterClientSecret set to true
    ## Defaults to false
    ## Ref: https://docs.pingcap.com/tidb-in-kubernetes/stable/configure-a-tidb-cluster#mountclusterclientsecret
    mountClusterClientSecret: false

    ## The default storageClassName of the persistent volume for PD data storage.
    ## Can be overwritten by `storageClassName` field in `storageVolumes` settings
    # storageClassName: ""

    ## defines volumes which uses PVCs as storage backend
    # storageVolumes:
    #   - name: pvcName  # this will be suffix of PVCs' name
    #     storageClassName: local-storage  # specify which storageClass to use
    #     storageSize: 1Gi  # storage request of PVC
    #     mountPath: /some/path  # mount path of the PVC

    ## Subdirectory within the volume to store PD Data. By default, the data
    ## is stored in the root directory of volume which is mounted at
    ## /var/lib/pd. Specifying this will change the data directory to a subdirectory,
    ## e.g. /var/lib/pd/data if you set the value to "data".
    ## It's dangerous to change this value for a running cluster as it will
    ## upgrade your cluster to use a new storage directory.
    ## Defaults to "" (volume's root).
    # dataSubDir: ""

    ## Affinity for pod scheduling
    ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    # affinity:
    #   podAntiAffinity:
    #     # prefer not to run pd pods on the same node which runs tidb/tikv pods
    #     preferredDuringSchedulingIgnoredDuringExecution:
    #       - podAffinityTerm:
    #           labelSelector:
    #             matchExpressions:
    #               - key: app.kubernetes.io/component
    #                 operator: In
    #                 values:
    #                   - tidb
    #                   - tikv
    #           topologyKey: kubernetes.io/hostname
    #         weight: 100
    #     # require not to run pd pods on nodes where there's already a pd pod running
    #     # if setting this, you must ensure that at least 3 nodes are available in the cluster
    #     requiredDuringSchedulingIgnoredDuringExecution:
    #       - labelSelector:
    #           matchExpressions:
    #             - key: app.kubernetes.io/component
    #               operator: In
    #               values:
    #                 - pd
    #         topologyKey: kubernetes.io/hostname

    ## set a different tidb client tls cert secret name than default $clusterName-tidb-client-secret
    ## only useful when TLS is enabled for TiDB client
    ## Ref: https://docs.pingcap.com/tidb-in-kubernetes/stable/enable-tls-for-mysql-client
    # tlsClientSecretName: custom-tidb-client-secret-name

  tidb:
    ############################
    # Basic TiDB Configuration #
    ############################

    ## Base image of the component
    baseImage: pingcap/tidb

    ## tidb-server Configuration
    ## Ref: https://docs.pingcap.com/tidb/stable/tidb-configuration-file
    config: {}

    ## The desired replicas
    replicas: 3

    ## max inprogress failover TiDB pod counts
    # maxFailoverCount: 3

    ## describes the compute resource requirements.
    ## Ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
    requests:
      cpu: 100m
      memory: 256Mi
      storage: 1Gi
    limits:
      cpu: 1000m
      memory: 2Gi
      storage: 10Gi

    ## defines Kubernetes service for tidb-server
    ## If you are in a public cloud environment, you can use cloud LoadBalancer to access the TiDB service
    ## if you are in a private cloud environment, you can use Ingress or NodePort, or ClusterIP and port forward (only for development)
    ## you can set mysqlNodePort and statusNodePort to expose server/status service to given NodePort
    service:
      type: NodePort
      externalTrafficPolicy: Local  # Ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
      # # which NodePort to expose 4000 (mysql) port of tidb-server, only effective when type=LoadBalancer/NodePort
      # mysqlNodePort: 30020
      # exposeStatus: true  # defaults to true
      # # which NodePort to expose 10080 (status) port of tidb-server, only effective when type=LoadBalancer/NodePort and exposeStatus=true
      # statusNodePort: 30040

    ###############################
    # Advanced TiDB Configuration #
    ###############################

    ## Overwrite TiDB cluster level configurations
    # version: "v4.0.8"
    # imagePullPolicy: IfNotPresent
    # ImagePullSecrets: secretName
    # hostNetwork: false
    # serviceAccount: advanced-tidb-tidb
    # priorityClassName: system-cluster-critical
    # schedulerName: tidb-scheduler
    # nodeSelector:
    #   app.kubernetes.io/component: tidb
    # annotations:
    #   node.kubernetes.io/instance-type: some-vm-type
    # tolerations:
    #   - effect: NoSchedule
    #     key: dedicated
    #     operator: Equal
    #     value: tidb
    # configUpdateStrategy: RollingUpdate
    # statefulSetUpdateStrategy: RollingUpdate

    ## List of environment variables to set in the container
    ## Note that the following env names cannot be used and may be overrided by TiDB Operator builtin envs
    ##   - NAMESPACE
    ##   - TZ
    ##   - SERVICE_NAME
    ##   - PEER_SERVICE_NAME
    ##   - HEADLESS_SERVICE_NAME
    ##   - SET_NAME
    ##   - HOSTNAME
    ##   - CLUSTER_NAME
    ##   - POD_NAME
    ##   - BINLOG_ENABLED
    ##   - SLOW_LOG_FILE
    ## Ref: https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/
    # env:
    #   - name: MY_ENV_1
    #     value: value1
    #   - name: MY_ENV_2
    #     valueFrom:
    #       fieldRef:
    #         fieldPath: status.myEnv2

    ## Custom sidecar containers can be injected into the TiDB pods,
    ## which can act as a logging/tracing agent or for any other use case
    # additionalContainers:
    #   - name: myCustomContainer
    #     image: ubuntu

    ## custom additional volumes in TiDB pods
    # additionalVolumes:
    #   - name: nfs
    #     nfs:
    #       server: 192.168.0.2
    #       path: /nfs

    ## custom additional volume mounts in TiDB pods
    # additionalVolumeMounts:
    #   - name: nfs
    #     mountPath: /nfs

    ## define the time period between pod Terminating and killed
    ## Ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#hook-handler-execution
    # terminationGracePeriodSeconds: 30s

    ## defines privilege and access control settings for TiDB pods
    ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
    # podSecurityContext:
    #   sysctls:
    #     - name: net.ipv4.tcp_syncookies
    #       value: 0

    ## prob tidb-server readiness
    ## valid type values:
    ##   - `tcp`, which uses Kubernetes TCPSocketAction to prob the 4000 tcp port of the pod
    ##   - `command`, which uses curl to access the /status path on port 10080 of the pod
    ## This is only supported after tidb v4.0.9, ref: https://github.com/pingcap/tidb/pull/20694
    # readinessProbe:
    #   type: command

    ## when enabled, TiDB will accept TLS encrypted connections from MySQL client
    ## Ref: https://docs.pingcap.com/tidb-in-kubernetes/stable/enable-tls-for-mysql-client
    # tlsClient:
    #   enabled: true

    ## MANUAL CONFIG NOT RECOMMENDED
    ## binlogEnabled will automatically be true if Pump is enabled, otherwise false
    ## set this manually if you really know what you are doing
    # binlogEnabled: false

    ## if enabled, slow log will be output into a separate sidecar container
    # separateSlowLog: true
    # # configures seperate sidecar container, where `image` & `imagePullPolicy` will be overwritten by
    # # the same field in `TidbCluster.helper`
    # slowLogTailer:
    #   requests:
    #     cpu: 100m
    #     memory: 256Mi
    #   limits:
    #     cpu: 200m
    #     memory: 512Mi
    #   image: busybox
    #   imagePullPolicy: IfNotPresent

    ## The default storageClassName of the persistent volume for TiDB data storage.
    ## Can be overwritten by `storageClassName` field in `storageVolumes` settings
    # storageClassName: ""

    ## defines volumes which uses PVCs as storage backend
    # storageVolumes:
    #   - name: pvcName  # this will be suffix of PVCs' name
    #     storageClassName: local-storage  # specify which storageClass to use
    #     storageSize: 1Gi  # storage request of PVC
    #     mountPath: /some/path  # mount path of the PVC

    ## config Kubernetes container lifecycle hooks for tidb-server pods
    ## Ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/
    # lifecycle:
    #   postStart:
    #   preStop:

    ## Affinity for pod scheduling
    ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    # affinity:
    #   podAntiAffinity:
    #     preferredDuringSchedulingIgnoredDuringExecution:
    #       - podAffinityTerm:
    #           labelSelector:
    #             matchExpressions:
    #               - key: app.kubernetes.io/component
    #                 operator: In
    #                 values:
    #                   - pd
    #                   - tikv
    #           topologyKey: kubernetes.io/hostname
    #         weight: 100
    #     # require not to run tidb pods on nodes where there's already a tidb pod running
    #     # if setting this, you must ensure that at least 3 nodes are available in the cluster
    #     requiredDuringSchedulingIgnoredDuringExecution:
    #       - labelSelector:
    #           matchExpressions:
    #             - key: app.kubernetes.io/component
    #               operator: In
    #               values:
    #                 - tidb
    #         topologyKey: kubernetes.io/hostname

  tikv:
    ############################
    # Basic TiKV Configuration #
    ############################

    ## Base image of the component
    baseImage: pingcap/tikv

    ## tikv-server configuration
    ## Ref: https://docs.pingcap.com/tidb/stable/tikv-configuration-file
    config: {}

    ## The desired replicas
    replicas: 3

    ## max inprogress failover TiKV pod counts
    # maxFailoverCount: 3

    ## describes the compute resource requirements.
    ## Ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
    requests:
      cpu: 100m
      memory: 256Mi
      storage: 1Gi
    limits:
      cpu: 1000m
      memory: 2Gi
      storage: 10Gi

    ###############################
    # Advanced TiKV Configuration #
    ###############################

    ## Overwrite TiDB cluster level configurations
    # version: "v4.0.8"
    # imagePullPolicy: IfNotPresent
    # ImagePullSecrets: secretName
    # hostNetwork: false
    # serviceAccount: advanced-tidb-tikv
    # priorityClassName: system-cluster-critical
    # schedulerName: tidb-scheduler
    # nodeSelector:
    #   app.kubernetes.io/component: tikv
    # annotations:
    #   node.kubernetes.io/instance-type: some-vm-type
    # tolerations:
    #   - effect: NoSchedule
    #     key: dedicated
    #     operator: Equal
    #     value: tikv
    # configUpdateStrategy: RollingUpdate
    # statefulSetUpdateStrategy: RollingUpdate

    ## List of environment variables to set in the container
    ## Note that the following env names cannot be used and may be overrided by TiDB Operator builtin envs
    ##   - NAMESPACE
    ##   - TZ
    ##   - SERVICE_NAME
    ##   - PEER_SERVICE_NAME
    ##   - HEADLESS_SERVICE_NAME
    ##   - SET_NAME
    ##   - HOSTNAME
    ##   - CLUSTER_NAME
    ##   - POD_NAME
    ##   - BINLOG_ENABLED
    ##   - SLOW_LOG_FILE
    ## Ref: https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/
    # env:
    #   - name: MY_ENV_1
    #     value: value1
    #   - name: MY_ENV_2
    #     valueFrom:
    #       fieldRef:
    #         fieldPath: status.myEnv2

    ## Custom sidecar containers can be injected into the TiKV pods,
    ## which can act as a logging/tracing agent or for any other use case
    # additionalContainers:
    #   - name: myCustomContainer
    #     image: ubuntu

    ## custom additional volumes in TiKV pods
    # additionalVolumes:
    #   - name: nfs
    #     nfs:
    #       server: 192.168.0.2
    #       path: /nfs

    ## custom additional volume mounts in TiKV pods
    # additionalVolumeMounts:
    #   - name: nfs
    #     mountPath: /nfs

    ## define the time period between pod Terminating and killed
    ## Ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#hook-handler-execution
    # terminationGracePeriodSeconds: 30s

    ## defines privilege and access control settings for TiKV pods
    ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
    # podSecurityContext:
    #   sysctls:
    #     - name: net.ipv4.tcp_syncookies
    #       value: 0

    ## when TLS cluster feature is enabled, TiDB Operator will automatically mount the certificates if mountClusterClientSecret set to true
    ## Defaults to false
    ## Ref: https://docs.pingcap.com/tidb-in-kubernetes/stable/configure-a-tidb-cluster#mountclusterclientsecret
    mountClusterClientSecret: false

    ## The default storageClassName of the persistent volume for TiKV data storage.
    ## Can be overwritten by `storageClassName` field in `storageVolumes` settings
    # storageClassName: ""

    ## defines volumes which uses PVCs as storage backend
    # storageVolumes:
    #   - name: pvcName  # this will be suffix of PVCs' name
    #     storageClassName: local-storage  # specify which storageClass to use
    #     storageSize: 1Gi  # storage request of PVC
    #     mountPath: /some/path  # mount path of the PVC

    ## run tikv container in previleged mode
    ## Processes in privileged containers are essentially equivalent to root on the host
    ## NOT RECOMMENDED in production environment
    ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#privileged
    # privileged: false

    ## Subdirectory within the volume to store TiKV Data. By default, the data
    ## is stored in the root directory of volume which is mounted at /var/lib/tikv.
    ## Specifying this will change the data directory to a subdirectory, e.g.
    ## /var/lib/tikv/data if you set the value to "data".
    ## It's dangerous to change this value for a running cluster as it will
    ## upgrade your cluster to use a new storage directory.
    ## Defaults to "" (volume's root).
    # dataSubDir: ""

    ## enable failover when tikv pod is failed
    # recoverFailover: true

    ## defines timeout period from the beginning of region leader eviction, after which the operator can safely delete the tikv pod
    # evictLeaderTimeout: 3m

    ## Affinity for pod scheduling
    ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    # affinity:
    #   podAntiAffinity:
    #     preferredDuringSchedulingIgnoredDuringExecution:
    #       - podAffinityTerm:
    #           labelSelector:
    #             matchExpressions:
    #               - key: app.kubernetes.io/component
    #                 operator: In
    #                 values:
    #                   - tidb
    #                   - pd
    #           topologyKey: kubernetes.io/hostname
    #         weight: 100
    #     # require not to run tidb pods on nodes where there's already a tidb pod running
    #     # if setting this, you must ensure that at least 3 nodes are available in the cluster
    #     requiredDuringSchedulingIgnoredDuringExecution:
    #       - labelSelector:
    #           matchExpressions:
    #             - key: app.kubernetes.io/component
    #               operator: In
    #               values:
    #                 - tikv
    #         topologyKey: kubernetes.io/hostname

  ## Deploy TiDB Binlog of a TiDB cluster
  ## Ref: https://pingcap.com/docs/tidb-in-kubernetes/stable/deploy-tidb-binlog/#deploy-pump
  # pump:
  #   baseImage: pingcap/tidb-binlog
  #   version: "v4.0.8"
  #   replicas: 1
  #   storageClassName: local-storage
  #   requests:
  #     storage: 1Gi
  #   imagePullPolicy: IfNotPresent
  #   ImagePullSecrets: secretName
  #   hostNetwork: false
  #   serviceAccount: advanced-tidb-pump
  #   priorityClassName: system-cluster-critical
  #   schedulerName: tidb-scheduler
  #   nodeSelector:
  #     app.kubernetes.io/component: pump
  #   annotations:
  #     node.kubernetes.io/instance-type: some-vm-type
  #   tolerations: {}
  #   configUpdateStrategy: RollingUpdate
  #   statefulSetUpdateStrategy: RollingUpdate
  #   podSecurityContext: {}
  #   env: []
  #   AdditionalContainers: []
  #   additionalVolumes: []
  #   additionalVolumeMounts: []
  #   terminationGracePeriodSeconds: 30s
  #   config:
  #     addr: 0.0.0.0:8250
  #     gc: 7
  #     heartbeat-interval: 2

  ## Ref: TiCDC is a tool for replicating the incremental data of TiDB
  ## Ref: https://pingcap.com/docs/tidb-in-kubernetes/stable/deploy-ticdc/
  # ticdc:
  #   baseImage: pingcap/ticdc
  #   version: "v4.0.8"
  #   replicas: 3
  #   storageClassName: local-storage
  #   requests:
  #     storage: 1Gi
  #   imagePullPolicy: IfNotPresent
  #   ImagePullSecrets: secretName
  #   hostNetwork: false
  #   serviceAccount: advanced-tidb-ticdc
  #   priorityClassName: system-cluster-critical
  #   schedulerName: tidb-scheduler
  #   nodeSelector:
  #     app.kubernetes.io/component: ticdc
  #   annotations:
  #     node.kubernetes.io/instance-type: some-vm-type
  #   tolerations: {}
  #   configUpdateStrategy: RollingUpdate
  #   statefulSetUpdateStrategy: RollingUpdate
  #   podSecurityContext: {}
  #   env: []
  #   AdditionalContainers: []
  #   additionalVolumes: []
  #   additionalVolumeMounts: []
  #   terminationGracePeriodSeconds: 30s

  ## Ref: https://pingcap.com/docs/tidb-in-kubernetes/stable/deploy-tiflash/
  # tiflash:
  #   baseImage: pingcap/tiflash
  #   version: "v4.0.8"
  #   replicas: 1
  #   maxFailoverCount: 3
  #   storageClassName: local-storage
  #   requests:
  #     storage: 1Gi
  #   imagePullPolicy: IfNotPresent
  #   ImagePullSecrets: secretName
  #   hostNetwork: false
  #   serviceAccount: advanced-tidb-tiflash
  #   priorityClassName: system-cluster-critical
  #   schedulerName: tidb-scheduler
  #   nodeSelector:
  #     app.kubernetes.io/component: tiflash
  #   annotations:
  #     node.kubernetes.io/instance-type: some-vm-type
  #   tolerations: {}
  #   configUpdateStrategy: RollingUpdate
  #   statefulSetUpdateStrategy: RollingUpdate
  #   podSecurityContext: {}
  #   env: []
  #   AdditionalContainers: []
  #   additionalVolumes: []
  #   additionalVolumeMounts: []
  #   terminationGracePeriodSeconds: 30s
  #   storageClaims:
  #     - resources:
  #         requests:
  #           storage: 1Gi
  #       storageClassName: local-storage
