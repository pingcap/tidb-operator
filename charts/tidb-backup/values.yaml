# Default values for tidb-backup.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# clusterName is the TiDB cluster name that should backup from or restore to.
clusterName: demo

# timezone is the default system timzone
timezone: UTC

mode: backup # backup | restore | scheduled-restore

# name is the backup dir name and pvc name for ad-hoc backup and restore
name: fullbackup-{{ date "200601021504" .Release.Time }}

# The default jobName is clusterName-name
# jobName:

# The TiDB host to connect to
# By default this will match a normal tidb-operator deploy
# host:

# scheduledBackupName is the name of a scheduled backup directory,
# used to restore the tidb cluster from scheduled backup.
# scheduledBackupName: scheduled-backup-20190822-041004

image:
  pullPolicy: IfNotPresent
  # https://github.com/pingcap/tidb-cloud-backup
  backup: pingcap/tidb-cloud-backup:20190828

# Add additional labels for backup/restore job's pod
# ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
extraLabels: {}

# secretName is the name of the secret which stores user and password used for backup/restore
# Note: you must give the user enough privilege to do the backup and restore
# you can create the secret by:
# kubectl create secret generic backup-secret --namespace=<namespace> --from-literal=user=root --from-literal=password=<password>
secretName: backup-secret

resources:
  limits:
    cpu: 4000m
    memory: 8Gi
  requests:
    cpu: 2000m
    memory: 4Gi

# Kubernetes service account to use
# serviceAccount:

storage:
  className: local-storage
  size: 100Gi

# -t is thread count, larger thread count will speed up the backup, but may impact the performance of the upstream TiDB.
# -F is the chunk size, a big table is partitioned into many chunks.
# Other useful options are -B for database, and -T for tables.
# See https://github.com/maxbube/mydumper/blob/master/docs/mydumper_usage.rst#options for more options.
backupOptions: "--compress-protocol -t 16 -F 256 --skip-tz-utc --verbose=3"

# Set the tidb_snapshot to be used for the backup
# Use `show master status` to get the ts:
#   MySQL [(none)]> show master status;
#   +-------------+--------------------+--------------+------------------+-------------------+
#   | File        | Position           | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
#   +-------------+--------------------+--------------+------------------+-------------------+
#   | tidb-binlog | 409076965619269635 |              |                  |                   |
#   +-------------+--------------------+--------------+------------------+-------------------+
#   1 row in set (0.01 sec)
# For this example, "409076965619269635" is the initialCommitTs
initialCommitTs: ""
# restoreOptions is the options of loader https://www.pingcap.com/docs-cn/tools/loader/
restoreOptions: "-t 16"
# The time limit during which data is retained for each GC when backup, in the format of Go Duration.
# When a GC happens, the current time minus this value is the safe point.
tikvGCLifeTime: 720h

# By default, the backup/restore uses PV to store/load backup data
# You can choose to store/load backup data to/from gcp, ceph or s3 bucket by enabling the following corresponding section:

# backup to or restore from gcp bucket, the backup path is in the form of <clusterName>-<name>
gcp: {}
  # bucket: ""
  # secretName is not necessary on GKE if you use the workload identity feature
  # secretName is the name of the secret which stores the gcp service account credentials json file
  # The service account must have read/write permission to the above bucket.
  # Read the following document to create the service account and download the credentials file as credentials.json:
  # https://cloud.google.com/docs/authentication/production#obtaining_and_providing_service_account_credentials_manually
  # And then create the secret by:
  # kubectl create secret generic gcp-backup-secret --namespace=<namespace> --from-file=./credentials.json
  # secretName: gcp-backup-secret

# backup to or restore from ceph bucket, the backup path is in the form of <clusterName>-<name>
ceph: {}
  # endpoint: ""
  # bucket: ""
  # secretName is the name of the secret which stores ceph object store access key and secret key
  # You can create the secret by:
  # kubectl create secret generic ceph-backup-secret --namespace=<namespace> --from-literal=access_key=<access-key> --from-literal=secret_key=<secret-key>
  # secretName: ceph-backup-secret

# backup to or restore from s3 bucket, the backup path is in the form of <clusterName>-<name>
s3: {}
  # region: ""
  # bucket: ""
  # secretName is the name of the secret which stores s3 object store access key and secret key
  # This is not necessary on AWS. Instead you should be able to get the credentials from the EKS service IAM role.
  # You can create the secret by:
  # kubectl create secret generic s3-backup-secret --namespace=<namespace> --from-literal=access_key=<access-key> --from-literal=secret_key=<secret-key>
  # secretName: s3-backup-secret
