# Default values for tidb-lightning.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# timezone is the default system timzone
timezone: UTC

image: pingcap/tidb-lightning:v5.1.0
imagePullPolicy: IfNotPresent
# imagePullSecrets: []

service:
  type: NodePort

# failFast causes the lightning pod fails when any error happens.
# when disabled, the lightning pod will keep running when error happens to allow manual intervention, users have to check logs to see the job status.
failFast: true

dataSource:
  # for `local` source, the `nodeName` should be the label value of `kubernetes.io/hostname`.
  local: {}
    # nodeName: kind-worker3
    # hostPath: /data/export-20190820
  # The backup data is on a PVC which is exported and unarchived from tidb-backup or scheduled backup.
  # Note: when using this mode, the lightning needs to be deployed in the same namespace as the PVC
  # and the `targetTidbCluster.namespace` needs to be configured explicitly
  adhoc: {}
    # pvcName: tidb-cluster-scheduled-backup
    # backupName: scheduled-backup-20190822-041004
  remote:
    rcloneImage: rclone/rclone:1.55.1
    storageClassName: local-storage
    storage: 100Gi
    secretName: cloud-storage-secret
    path: s3:bench-data-us/sysbench/sbtest_16_1e7.tar.gz
    # Directory support downloading all files in a remote directory, shadow dataSoure.remote.path if present
    # directory: s3:bench-data-us
    # If rcloneConfig is configured, then `secretName` will be ignored,
    # `rcloneConfig` should only be used for the cases where no sensitive
    # information need to be configured, e.g. the configuration as below,
    # the Pod will get the credentials from the infrastructure.
    #rcloneConfig: |
    #  [s3]
    #  type = s3
    #  provider = AWS
    #  env_auth = true
    #  region = us-west-2

targetTidbCluster:
  name: tidb-cluster
  # namespace is the target tidb cluster namespace, can be omitted if the lightning is deployed in the same namespace of the target tidb cluster
  namespace: ""
  user: root
  # If the `secretName` and `secretUserKey` are set,
  # the `user` will be ignored and the user in the
  # `secretName` will be used by lightning.
  # If the `secretName` and `secretPwdKey` are set, the
  # password in the `secretName` will be used by lightning.
  #secretName: ""
  #secretUserKey: user
  #secretPwdKey: password

# Whether enable the TLS connection between TiDB cluster components.
# If enabled, a Secret named "<targetTidbCluster.name>-lightning-cluster-secret" must exist.
# To create this Secret: kubectl create secret generic <targetTidbCluster.name>-lightning-cluster-secret --namespace=<namespace> --from-file=tls.crt=<path/to/tls.crt> --from-file=tls.key=<path/to/tls.key> --from-file=ca.crt=<path/to/ca.crt>
# NOTE: if tlsCluster enabled but tlsClient not enabled, then you should add the following TOML config items into `config`:
#  [tidb]
#  tls="false"
tlsCluster: {}
  # enabled: true

# Whether enable the TLS connection with the TiDB MySQL protocol port.
# if enabled, a Secret named `tlsClientSecretName` (if specified) or `${targetTidbCluster.name}-tidb-client-secret` must exist.
# To create this Secret: kubectl create secret generic ${targetTidbCluster.name}-tidb-client-secret --namespace=<namespace> --from-file=tls.crt=<path/to/tls.crt> --from-file=tls.key=<path/to/tls.key> --from-file=ca.crt=<path/to/ca.crt>
tlsClient: {}
  # enabled: true
  # tlsClientSecretName: ${targetTidbCluster.name}-tidb-client-secret

resources: {}
  # limits:
  #  cpu: 16000m
  #  memory: 8Gi
  # requests:
  #  cpu: 16000m
  #  memory: 8Gi

nodeSelector: {}

annotations: {}

tolerations: []
affinity: {}

# The delivery backend used to import data (valid options include `importer`, `local` and `tidb`).
# If set to `local`, then the following `sortedKV` should be set.
backend: importer

# For `local` backend, an extra PV is needed for local KV sorting.
sortedKV: {}
#  storageClassName: local-storage
#  storage: 100Gi

# Specify a Service Account for lightning
# serviceAccount:

# For TiDB-Lightning v3.0.18+ or v4.0.3+, if you want to log to stdout, you should set `file = "-"`.
# If you want to store the checkpoint under source data directory, you should set `CHECKPOINT_USE_DATA_DIR` as the prefix of `dsn`.
# If you do not update the `CHECKPOINT_USE_DATA_DIR` in the following `dsn` field, it will be replaced automatically in the startup script with the following rules:
# for `local` data source, `CHECKPOINT_USE_DATA_DIR` is replaced by `hostPath`;
# for `adhoc` data source, `CHECKPOINT_USE_DATA_DIR` is replaced by the path to `backupName` (`pvcName` if `backupName` is not specified) in `pvcName` PVC;
# for `remote` data source, `CHECKPOINT_USE_DATA_DIR` is replaced by the path of the backup data in the PVC requested by this chart.
config: |
  [lightning]
  level = "info"
  file = "-"
  [checkpoint]
  enable = true
  driver = "file"
  dsn = "CHECKPOINT_USE_DATA_DIR/tidb_lightning_checkpoint.pb"
  keep-after-success = false
